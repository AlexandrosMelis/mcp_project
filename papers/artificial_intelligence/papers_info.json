{
  "2110.01831v1": {
    "title": "The Artificial Scientist: Logicist, Emergentist, and Universalist Approaches to Artificial General Intelligence",
    "authors": [
      "Michael Timothy Bennett",
      "Yoshihiro Maruyama"
    ],
    "summary": "We attempt to define what is necessary to construct an Artificial Scientist, explore and evaluate several approaches to artificial general intelligence (AGI) which may facilitate this, conclude that a unified or hybrid approach is necessary and explore two theories that satisfy this requirement to some degree.",
    "pdf_url": "https://arxiv.org/pdf/2110.01831v1",
    "published": "2021-10-05"
  },
  "2110.01835v1": {
    "title": "Compression, The Fermi Paradox and Artificial Super-Intelligence",
    "authors": [
      "Michael Timothy Bennett"
    ],
    "summary": "The following briefly discusses possible difficulties in communication with and control of an AGI (artificial general intelligence), building upon an explanation of The Fermi Paradox and preceding work on symbol emergence and artificial general intelligence. The latter suggests that to infer what someone means, an agent constructs a rationale for the observed behaviour of others. Communication then requires two agents labour under similar compulsions and have similar experiences (construct similar solutions to similar tasks). Any non-human intelligence may construct solutions such that any rationale for their behaviour (and thus the meaning of their signals) is outside the scope of what a human is inclined to notice or comprehend. Further, the more compressed a signal, the closer it will appear to random noise. Another intelligence may possess the ability to compress information to the extent that, to us, their signals would appear indistinguishable from noise (an explanation for The Fermi Paradox). To facilitate predictive accuracy an AGI would tend to more compressed representations of the world, making any rationale for their behaviour more difficult to comprehend for the same reason. Communication with and control of an AGI may subsequently necessitate not only human-like compulsions and experiences, but imposed cognitive impairment.",
    "pdf_url": "https://arxiv.org/pdf/2110.01835v1",
    "published": "2021-10-05"
  },
  "2204.10358v1": {
    "title": "Creative Problem Solving in Artificially Intelligent Agents: A Survey and Framework",
    "authors": [
      "Evana Gizzi",
      "Lakshmi Nair",
      "Sonia Chernova",
      "Jivko Sinapov"
    ],
    "summary": "Creative Problem Solving (CPS) is a sub-area within Artificial Intelligence (AI) that focuses on methods for solving off-nominal, or anomalous problems in autonomous systems. Despite many advancements in planning and learning, resolving novel problems or adapting existing knowledge to a new context, especially in cases where the environment may change in unpredictable ways post deployment, remains a limiting factor in the safe and useful integration of intelligent systems. The emergence of increasingly autonomous systems dictates the necessity for AI agents to deal with environmental uncertainty through creativity. To stimulate further research in CPS, we present a definition and a framework of CPS, which we adopt to categorize existing AI methods in this field. Our framework consists of four main components of a CPS problem, namely, 1) problem formulation, 2) knowledge representation, 3) method of knowledge manipulation, and 4) method of evaluation. We conclude our survey with open research questions, and suggested directions for the future.",
    "pdf_url": "https://arxiv.org/pdf/2204.10358v1",
    "published": "2022-04-21"
  }
}